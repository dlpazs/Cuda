# Tensor RT

A platform for deploying DL models onto the GPU deployable to embedded devices and onto datacenters.
It increases throughput and reducing latency during inference. TensorRt provides APIs and parses to import trained models from all
frameworks. 
